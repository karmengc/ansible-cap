---

- include: authorize_keys.yml

- name: Disable Ipv6
  blockinfile:
    block: |
      net.ipv6.conf.all.disable_ipv6 = 1
      net.ipv6.conf.default.disable_ipv6 = 1
      net.ipv6.conf.lo.disable_ipv6 = 1
      net.ipv6.conf.all.disable_ipv6 = 1
      net.ipv6.conf.default.disable_ipv6 = 1
      net.ipv6.conf.lo.disable_ipv6 = 1
    dest: "/etc/sysctl.conf"
    insertafter: EOF

- name: Ensure Hadoop install dir exists
  file:
    path: "{{ hadoop_install_dir }}"
    mode: 0755
    state: directory
    follow: true
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"

- name: Download Hadoop
  get_url:
    url: "{{ hadoop_mirror }}/hadoop-{{ hadoop_version }}/hadoop-{{ hadoop_version }}.tar.gz"
    dest: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"

- name: Extract Hadoop
  unarchive:
    src: "/tmp/hadoop-{{ hadoop_version }}.tar.gz"
    dest: "{{ hadoop_install_dir }}"
    copy: no
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
    creates: "{{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}"

- name: Create symbolic link usr local
  file:
    src: "{{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}"
    path: "/usr/local/hadoop"
    state: link
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"

- name: Create symbolic link opt
  file:
    src: "{{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}"
    path: "/opt/hadoop"
    state: link
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"

- name: Set var log hadoop perms
  file:
    path: "/var/log/hadoop"
    state: directory
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
    mode: 0755

- name: Set bash profile
  blockinfile:
    block: |
      export JAVA_HOME=$(dirname $(dirname $(readlink $(readlink $(which java)))))
      export PATH=$PATH:$JAVA_HOME/bin
      export CLASSPATH=.:$JAVA_HOME/jre/lib:$JAVA_HOME/lib:$JAVA_HOME/lib/tools.jar
      #Hadoop
      export HADOOP_HOME=/opt/hadoop
      export PATH=$PATH:/opt/hadoop/bin
      export PATH=$PATH:/opt/hadoop/sbin
      export HADOOP_MAPRED_HOME=/opt/hadoop
      export HADOOP_COMMON_HOME=/opt/hadoop
      export HADOOP_HDFS_HOME=/opt/hadoop
      export YARN_HOME=/opt/hadoop
      export YARN_CONF_DIR=/opt/hadoop/etc/hadoop
      export HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      if ! pgrep -u "$USER" ssh-agent > /dev/null; then
        ssh-agent > ~/.ssh-agent-thing
      fi
      if [[ "$SSH_AGENT_PID" == "" ]]; then
        eval "$(<~/.ssh-agent-thing)"
        echo "HOLA"
      fi
    dest: "/home/{{ hadoop_user }}/.bash_profile"
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
    insertafter: 'EOF'
    create: yes
    state: present

- name: Configure Hadoop environment hadoop.env.sh
  copy:
    src: hadoop-env.sh
    dest: "{{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}/etc/hadoop/hadoop-env.sh"
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
  notify: "Restart all hadoop from master"

- name: Configure Hadoop core-site.xml
  copy:
    src: core-site.xml
    dest: "{{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}/etc/hadoop/core-site.xml"
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
  notify: "Restart all hadoop from master"

- name: Configure Hadoop hdfs-site.xml
  template:
    src: hdfs-site.xml.j2
    dest: "{{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}/etc/hadoop/hdfs-site.xml"
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
  notify: "Restart all hadoop from master"


- name: Create namenode and datanode dirs
  file:
    path: "{{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}/hadoop_data/hdfs/{{ item }}"
    state: "directory"
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
  with_items:
    - namenode
    - datanode
  register: folders_created

- name: Launch Hadoop at Master
  shell: |
    {{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}/bin/hdfs namenode -format
  become: yes
  become_user: "{{ hadoop_user }}"
  #ignore_errors: true
  when: ansible_hostname == "master" and folders_created is changed

- name: Configure Hadoop slaves
  template:
    src: slaves.j2
    dest: "{{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}/etc/hadoop/slaves"
    owner: "{{ hadoop_user }}"
    group: "{{ hadoop_user }}"
  notify: "Restart all hadoop from master"
  when: ansible_hostname == "master"

- name: Delete 127.0.0.1 line at master
  lineinfile:
    path: "/etc/hosts"
    regexp: '^127\.0\.0\.1'
    state: "absent"
  when: ansible_hostname == "master"

- name: Set etc_hosts
  blockinfile:
    path: "/etc/hosts"
    insertafter: EOF
    block: |
      {{ hadoop_master_ip }} master
      {{ hadoop_worker_ip }} worker

- name: Check if Hadoop is runnning on Worker
  shell: jps | grep DataNode
  ignore_errors: yes
  register: hadoop_running_worker
  when: ansible_hostname == "worker"

- debug: var=hadoop_running_worker.rc
  when: ansible_hostname == "worker"

- name: Check if Hadoop is already runnning on Master
  shell: jps | grep NameNode
  ignore_errors: yes
  register: hadoop_running_master
  when: ansible_hostname == "master"

- debug: var=hadoop_running_master.rc
  when: ansible_hostname == "master"

- name: Launch Hadoop at Master (2)
  shell: |
    {{ hadoop_install_dir }}/hadoop-{{ hadoop_version }}/sbin/start-all.sh
  become: yes
  become_user: "{{ hadoop_user }}"
  #ignore_errors: true
  when: ansible_hostname == "master" and hadoop_running_master.rc == 1

- include: test_app.yml
  when: ansible_hostname == "master" and hadoop_test_app == true


# vim: ff=unix:ai:et:sw=2:ts=2:
