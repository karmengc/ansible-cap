---

- name: Stop Spark Standalone
  shell: |
    {{ spark_install_dir }}/spark-{{ spark_version }}/sbin/stop-all.sh
  become: yes
  become_user: "{{ spark_user }}"

- name: Add Mesosphere repo
  shell: |
    rpm -Uvh http://repos.mesosphere.io/el/7/noarch/RPMS/mesosphere-el-repo-7-1.noarch.rpm
  ignore_errors: true

- name: Install Mesos packages
  yum:
    name:
      - mesos
      - mesosphere-zookeeper
      - autoconf
      - libtool
        #- build-essential en centos gcc gcc-c++ make 
      - gcc
      - gcc-c++
      - make
      - python-devel
      - python-six
      - python-virtualenv
        #- libcurl14-nss-dev
      - libcurl-devel
        #- libsasl2-devel
        #- libsasl2-modules
      - maven
        #- libapr1-devel
        #- libsvn-devel
    state: present

- name: Start Mesos service at master
  service:
    name: "mesos-master"
  when: ansible_hostname == "master"

- name: Start Mesos service at slave
  service:
    name: "mesos-slave"
  when: ansible_hostname == "worker"

- name: Set Mesos Conf at Spark
  blockinfile:
    block: |
      export MESOS_NATIVE_JAVA_LIBRARY=/opt/mesos/build/src/.libs/libmesos.so
      export SPARK_EXECUTOR_URI=/tmp/spark-{{ spark_version }}.tgz
    dest: "{{ spark_install_dir }}/spark-{{ spark_version }}/conf/spark-env.sh"
    owner: "{{ spark_user }}"
    group: "{{ spark_user }}"
    insertafter: 'EOF'
    create: yes
    state: present

- name: test mesos message
  debug:
    msg: "Por favor ejecute lo siguiente (como sparkuser):
          mesos-master.sh —ip={{ spark_master_ip }}:5050 --work_dir=/tmp/mesos (en el nodo master)
          mesos-slave.sh --master={{ spark_master_ip }}:5050 --work_dir=/tmp/mesos --no-systemd_enable_support (en el nodo esclavo)
          compruebe que puede acceder a la interfaz de Mesos en http://{{ spark_master_ip }}:5050
    y por último ejecute lo siguiente para probar el funcionamiento:
          {{ spark_install_dir }}/spark-{{ spark_version }}/bin/spark-submit --master mesos://{{ spark_master_ip }}:5050 /tmp/WordCount.jar hdfs://{{ spark_master_ip }}::8020/prueba/texto.txt hdfs://{{ spark_master_ip }}:8020/prueba/resultadoMesos"

# vim: ff=unix:ai:et:sw=2:ts=2:
